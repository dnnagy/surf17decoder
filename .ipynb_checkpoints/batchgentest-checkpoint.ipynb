{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Concatenate, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "X_shape = (20, 8) # each X consists of 20 samples of 8 features\n",
    "y_shape = (1,) # the result is 1 bit\n",
    "\n",
    "class BatchGen:\n",
    "  def __init__(self, batch_size=16):\n",
    "    self.batch_size=batch_size\n",
    "    self.data_length = 256 # 256 (X, y) pairs in our fictional database\n",
    "    \n",
    "    # Generate random data\n",
    "    self.X = np.random.randint(0,2,size=(self.data_length, *X_shape))\n",
    "    self.y = np.random.randint(0,2,size=(self.data_length, *y_shape))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return int(np.ceil(self.data_length/float(self.batch_size)))\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    slc = slice(index*self.batch_size, (index+1)*self.batch_size)\n",
    "    return (self.X[slc], self.y[slc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoder:\n",
    "    def __init__(self, xshape, hidden_size=64):\n",
    "        self.hidden_size=hidden_size\n",
    "        self.xshape=xshape\n",
    "        pass\n",
    "    \n",
    "    def create_model(self):\n",
    "        # This returns a tensor\n",
    "        input_syndr = Input(shape=(self.xshape))\n",
    "        \n",
    "        x = LSTM(self.hidden_size, return_sequences=True)(input_syndr)\n",
    "        x = LSTM(self.hidden_size, return_sequences=True)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(self.hidden_size, activation='relu')(x)\n",
    "        predictions = Dense(1, activation='softmax')(x)\n",
    "        \n",
    "        # optimizer\n",
    "        sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "        \n",
    "        model = Model(inputs=input_syndr, outputs=predictions)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.967592, 0.4375]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg=BatchGen()\n",
    "model=SimpleDecoder(xshape=X_shape).create_model()\n",
    "model.train_on_batch(bg.__getitem__(0)[0], bg.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
